# Get started

## Clone

```shell
git clone --recursive https://github.com/MaastrichtU-IDS/data2services-transform-repository
```

## Build

Uses [data2services-sparql-operations](https://github.com/MaastrichtU-IDS/data2services-sparql-operations).

```shell
docker build -t data2services-sparql-operations ./data2services-transform-repository/data2services-sparql-operations
```

## Run

Transform datasets from generic RDF generated by the [Data2Services pipeline](https://github.com/MaastrichtU-IDS/data2services-pipeline) to the [BioLink](https://github.com/biolink/biolink-model) model (e.g. Drugbank or HGNC)

```shell
# Command to load in local GraphDB
docker run -it --rm --link graphdb:graphdb \
  -v "$PWD/data2services-insert/insert-biolink":/data \
  data2services-sparql-operations -f "/data" \
  -ep "http://graphdb:7200/repositories/test/statements" \
  -un MYUSERNAME -pw MYPASSWORD \
  -var serviceUrl:http://localhost:7200/repositories/test inputGraph:https://w3id.org/data2services/graph/input outputGraph:https://w3id.org/data2services/graph/output
```



## Execute on specific datasets

```shell
# DrugBank
docker run -it --rm -v "$PWD/insert-biolink/drugbank":/data \
	data2services-sparql-operations \
	-f "/data" -un USERNAME -pw PASSWORD \
	-ep "http://graphdb.dumontierlab.com/repositories/ncats-red-kg/statements" \
    -var serviceUrl:http://localhost:7200/repositories/test inputGraph:https://w3id.org/data2services/graph/xml2rdf outputGraph:https://w3id.org/data2services/biolink/drugbank

# HGNC
docker run -it --rm -v "$PWD/insert-biolink/hgnc":/data \
	data2services-sparql-operations \
	-f "/data" -un USERNAME -pw PASSWORD \
	-ep "http://graphdb.dumontierlab.com/repositories/ncats-red-kg/statements" \
	-var serviceUrl:http://localhost:7200/repositories/test inputGraph:https://w3id.org/data2services/graph/autor2rml outputGraph:https://w3id.org/data2services/biolink/hgnc
```


# Use SPARQL for conversion

Generating 2 types of generic SPARQL:

* From tabular (csv, tsv, RDBMS)
* From complex structure (XML, JSON, YAML)

### How we do

* For each attribute/node extracted we look for corresponding classes in BioLink Ontology

https://biolink.github.io/biolink-model/

https://raw.githubusercontent.com/biolink/biolink-model/master/ontology/biolink.ttl

https://bioportal.bioontology.org/ontologies/BLM

* TSV
  * Opening TSV file with calc and looking for concept matching columns in BioLink ontology
  * Opening  the Mapping file to get the exact URI of the column
* XML: using the schema printed by xml2rdf and the original XML file to look for matching concepts in BioLink ontology



### Limitations

* Needs to know really well the BioLink model
  * Can be hard to find some matching concepts in BioLink
  * What to do if no matching concept in BioLink?

* We can't build one big construct query. It needs to be divided in little construct queries with a focused goal
  * E.g.: getting targets infos
  * We need to avoid having too much query getting different arrays (result is a cartesian product)
* Problem: we first get all the hasChild and then filter on the type
  * **Why not putting the XPath directly in the predicate?**
* We can't split one statement value into multiple ("apple, orange" to "apple" and "orange")

### Enhancement

Also generating a generic construct query when generating the generic RDF (with AutoR2RML and xml2rdf) 

Then we "just" have to match it with the right bioentity class

* Automatically generate SPARQL query

The programs that do the generic RDF transformation should generate a file formally describing the data structure that is then used to generate the SPARQL construct query 

* Recommend class from an existing datamodel
  * Based on attribute name in the original file
  * Based on data 



# Use [RML](http://rml.io/) for conversion

### [RMLStreamer](https://github.com/RMLio/RMLStreamer)

Scala implementation, require to run Kafka and Flink.

Documentation about running on Docker will be released soon.

### [RMLMapper](https://github.com/RMLio/rmlmapper-java)

Java implementation, not used because of scalability issues.

```shell
# Build
mvn clean package -DskipTests
# Run
java -jar /home/vemonet/sandbox/rmlmapper-java/target/rmlmapper-4.1.0-r55-jar-with-dependencies.jar -c /data/drugbank/drugbank_config.properties
```

### [RocketRML](https://github.com/semantifyit/RocketRML)

NodeJS implementation focusing on XML and JSON conversion.